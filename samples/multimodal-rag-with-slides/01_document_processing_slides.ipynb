{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efca078b-efd1-47b6-b640-555f02e0e5d1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Data ingestion for multimodal RAG with presentation slides "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6af1d-3462-4383-bda4-deb237a0e155",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477aca4-bc8d-43f0-8a80-b9d7bc8b78b7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install PyMuPDF openai azure-identity azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92729dda-f2e7-46b6-b132-bc48511f156a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3896a88-63b1-4ce8-97a9-842051def6e8",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = \"<your-azure-openai-endpoint>\"\n",
    "AZURE_OPENAI_API_KEY = \"<your-azure-openai-api-key>\"\n",
    "AZURE_AI_SEARCH_ENDPOINT =\"<your-azure-ai-search-endpoint>\"\n",
    "AZURE_AI_SEARCH_ADMIN_KEY = \"<your-azure-ai-search-admin-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5c533-b4ba-4200-a30c-14e04191fa11",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Initialize Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be1081-3b2a-4839-9266-5fa371148226",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "aoai_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-10-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb56864-7ca6-47f4-b8e8-0f1fbe586963",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Generate description and embedding for each slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc2538-fe0e-4c15-8d85-c92a123698f2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_bytes):\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "def generate_description(base64_image):\n",
    "    system_message = \"\"\"You are an expert in analyzing and describing technical presentation slides for search and retrieval.\n",
    "    You are given a screenshot from a presentation slide.\n",
    "    Analyze the content of this presentation slide and generate a concise, clear summary.\n",
    "    Ensure the summary captures the core idea in a way that is useful for search and retrieval.\n",
    "    Identify key points, technical concepts, and relationships between different elements.\n",
    "    Use precise technical language appropriate for a knowledgeable audience.\n",
    "    Identify title and summarize the main topic and any subheadings.\n",
    "    Transcribe and explain text elements, bullet points, and messages.\n",
    "    If the slide contains images, diagrams, charts, or graphs, describe their purpose and what insights they convey including color, labels, trends, relationships and data insights.\n",
    "    Maintain clarity and accuracy in the description.\n",
    "    Do not mention page number or data or any information in the footer.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"Analyze the given screenshot of a presentation slide and provide a detailed description that can be used for search and retrieval purposes.\"\"\"\n",
    "\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_embedding(text):\n",
    "    response = aoai_client.embeddings.create(\n",
    "        input = text,\n",
    "        model= \"text-embedding-3-large\"\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb87d96-6685-4301-928f-b6d92613e5cb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "file_path = \"/lakehouse/default/Files/sample-slides.pdf\"\n",
    "document = fitz.open(file_path)\n",
    "\n",
    "docs = []\n",
    "id = 1\n",
    "for page in document:  # iterate through the pages\n",
    "    pix = page.get_pixmap()  # render page to an image\n",
    "    image_bytes = pix.tobytes()  # convert image to bytes\n",
    "    base64_image = encode_image(image_bytes)  # encode image to base64\n",
    "    description = generate_description(base64_image)  # generate description\n",
    "    embedding = generate_embedding(description)  # generate embedding\n",
    "    doc = {\n",
    "        \"id\": str(id),\n",
    "        \"page\": page.number + 1,\n",
    "        \"base64_image\": base64_image,\n",
    "        \"content\": description,\n",
    "        \"content_vector\": embedding\n",
    "    }\n",
    "    docs.append(doc)\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32686f85-0301-402c-890b-eca9dbc5b793",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "for doc in docs:\n",
    "    display(Image(data=base64.b64decode(doc[\"base64_image\"])))\n",
    "    display(Markdown(doc[\"content\"]))\n",
    "    print(50 * \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b04ca8-588a-4335-8e6f-2bae36e46e8d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Initialize Azure AI Search index client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e58db-4534-4271-97c3-02f704fcd205",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "search_index_client = SearchIndexClient(\n",
    "    endpoint=AZURE_AI_SEARCH_ENDPOINT, credential=AzureKeyCredential(key=AZURE_AI_SEARCH_ADMIN_KEY)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5ae93-5dcc-44d3-ae49-a38ce794caf6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237beb6-2c18-4cca-8627-2ebfc229e3aa",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SemanticSearch,\n",
    "    SearchField,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex,\n",
    ")\n",
    "\n",
    "\n",
    "# The fields we want to index. The \"content_vector\" field is a vector field that will be used for vector search.\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SimpleField(name=\"page\", type=SearchFieldDataType.Int64),\n",
    "    SimpleField(name=\"base64_image\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=3072,  # Dimension of embedding with text-embedding-3-large\n",
    "        vector_search_profile_name=\"my-hnsw-profile\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# For vector search, we want to use the HNSW (Hierarchical Navigable Small World)\n",
    "# algorithm (a type of approximate nearest neighbor search algorithm) with cosine\n",
    "# distance.\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"my-hnsw-config\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=1000,\n",
    "                ef_search=1000,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "            ),\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "            name=\"my-eknn-config\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(metric=VectorSearchAlgorithmMetric.COSINE),\n",
    "        ),\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"my-hnsw-profile\",\n",
    "            algorithm_configuration_name=\"my-hnsw-config\",\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"my-eknn-profile\",\n",
    "            algorithm_configuration_name=\"my-eknn-config\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# The \"content\" field should be prioritized for semantic ranking.\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"default\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[SemanticField(field_name=\"content\")],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create search index\n",
    "index_name = \"docs\"\n",
    "search_index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=fields,\n",
    "    semantic_search=semantic_search,\n",
    "    vector_search=vector_search,\n",
    ")\n",
    "search_index_client.create_index(search_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb8f3e-2584-48c7-a6ad-b44f7553aafa",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Upload documents to search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33848df2-cc26-40d9-802d-6436d14d54be",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "# Add the documents to the index using the Azure AI Search client\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_AI_SEARCH_ENDPOINT,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(key=AZURE_AI_SEARCH_ADMIN_KEY),\n",
    ")\n",
    "\n",
    "search_client.upload_documents(docs)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "93fea2a9-4c43-4373-ac3d-dc97bdb92eb4",
    "default_lakehouse_name": "Test_Lakehouse",
    "default_lakehouse_workspace_id": "db6f68a8-d7ce-47e9-a4e7-5c189e4a8066",
    "known_lakehouses": [
     {
      "id": "93fea2a9-4c43-4373-ac3d-dc97bdb92eb4"
     }
    ]
   }
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
