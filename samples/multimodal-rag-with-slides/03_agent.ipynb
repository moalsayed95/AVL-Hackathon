{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Agent with Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects azure-identity azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure AI Foundry project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.search.documents  import SearchClient\n",
    "\n",
    "# Get connection string for project\n",
    "project_connection_string = \"<your_project_connection_string>\"\n",
    "\n",
    "# Create a project client using environment variables loaded from the .env file\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    conn_str=project_connection_string, credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "# Create chat and embeddings clients using the project client\n",
    "chat_client = project_client.inference.get_chat_completions_client()\n",
    "embeddings_client = project_client.inference.get_embeddings_client()\n",
    "\n",
    "# Use the project client to get the default search connection\n",
    "# Before you need to create a connection in the Azure AI Foundry portal\n",
    "search_connection = project_client.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_AI_SEARCH, include_credentials=True\n",
    ")\n",
    "\n",
    "# Create a search client using the search connection\n",
    "search_client = SearchClient(\n",
    "    index_name=\"docs\",\n",
    "    endpoint=search_connection.endpoint_url,\n",
    "    credential=AzureKeyCredential(key=search_connection.key),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Enable tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have created an Application Insights resource for your Azure AI Foundry hub before running this code.\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace\n",
    "\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RAG function as a tool in function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.ai.inference.prompts import PromptTemplate\n",
    "from azure.search.documents.models import QueryAnswerType, QueryCaptionType, QueryType, VectorizedQuery\n",
    "from typing import Any, Callable, Set\n",
    "\n",
    "#@tracer.start_as_current_span(name=\"get_search_query\")  # Uncomment this line to enable tracing for this function\n",
    "# Define a function to generate a search query\n",
    "def get_search_query(user_question: str):\n",
    "    prompt_template_str = \"\"\"\n",
    "    system:\n",
    "    # Instructions\n",
    "    - You are an AI assistant.\n",
    "    - Given the user's question, respond with a search query that can be used to retrieve relevant documents for the user's question based on the intent.\n",
    "    - Be specific in what the user is asking about.\n",
    "    - Provide only the search query in the response.\n",
    "\n",
    "    # Example\n",
    "    With a user query like below:\n",
    "    \"What was the total revenue in 2024?\"\n",
    "\n",
    "    Respond with:\n",
    "    \"total revenue in 2024\"\n",
    "\n",
    "    user:\n",
    "    Return the search query for the following user question:\n",
    "    {{user_question}}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = PromptTemplate.from_string(prompt_template=prompt_template_str)\n",
    "\n",
    "    messages = prompt_template.create_messages(user_question=user_question)\n",
    "\n",
    "    response = chat_client.complete(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    search_query = response.choices[0].message.content\n",
    "\n",
    "    return search_query\n",
    "\n",
    "#@tracer.start_as_current_span(name=\"get_documents\")  # Uncomment this line to enable tracing for this function\n",
    "# Define a function that retrieves documents from the search index based on a search query\n",
    "def get_documents(search_query: str):\n",
    "    # Embed the search query\n",
    "    embedding = embeddings_client.embed(model=\"text-embedding-3-large\", input=search_query)\n",
    "    search_vector = embedding.data[0].embedding\n",
    "\n",
    "    # Search the index for document chunks matching the search query\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=search_vector,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"content_vector\"\n",
    "    )\n",
    "\n",
    "    search_results = search_client.search(\n",
    "        search_text=search_query,\n",
    "        vector_queries=[vector_query],\n",
    "        query_type=QueryType.SEMANTIC, semantic_configuration_name=\"default\", query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=5,\n",
    "        select=[\"id\", \"page\", \"base64_image\", \"content\"]\n",
    "    )\n",
    "\n",
    "    documents = [\n",
    "        {\n",
    "            \"id\": result[\"id\"],\n",
    "            \"page\": result[\"page\"],\n",
    "            \"base64_image\": result[\"base64_image\"],\n",
    "            \"content\": result[\"content\"]\n",
    "        }\n",
    "        for result in search_results\n",
    "    ]\n",
    "\n",
    "    return documents\n",
    "\n",
    "#@tracer.start_as_current_span(name=\"get_ansewr_from_documents\")  # Uncomment this line to enable tracing for this function\n",
    "# Define a function that generates an answer with documents\n",
    "def get_answer_from_documents(user_question: str, documents: list):\n",
    "    system_prompt = \"\"\"\n",
    "    - You are an expert helping employees from AVL to find information in the knowledge base of AVL.\n",
    "    - You are given a user question and a set of text descriptions and screenshots of slides from a presentation.\n",
    "    - Use the text descriptions and screenshots as context to answer the questions as completely, correctly, and concisely as possible.\n",
    "    - Not all documents are relevant to the question, so only use the relevant documents to answer the question.\n",
    "    - Don't try to make up any answers. If the answer cannot be retrieved from the context and you do not know the answer, then answer 'Sorry, I do not know.'.\n",
    "    - Add sources to the answer listing the page numbers you used and that are relevant to answer the question.\n",
    "    - The final response must be in JSON format with two fields:\n",
    "        - answer: The generated answer to the user's question.\n",
    "        - sources: A list of page numbers for each cited source\n",
    "    - Do not use ```json```\n",
    "\n",
    "    Here is an example of the final response:\n",
    "    {\n",
    "        \"answer\": \"The total revenue in 2024 was $245,122 million.\"\n",
    "        \"sources\": [1]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    context = \"\\n\\n\".join(f\"Document ID: {document['id']}\\nPage: {document['page']}\\nContent:\\n{document['content']}\" for document in documents)\n",
    "    user_prompt = f\"\"\"User: {user_question}\\n\\n\n",
    "    Answer the user's question based on the following context:\\n\\nDocuments:\\n\\n{context}\"\"\"\n",
    "    user_content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    images = [{ \"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{document['base64_image']}\"} } for document in documents]\n",
    "    user_content += images\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = chat_client.complete(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    result_str = response.choices[0].message.content\n",
    "    result_json = json.loads(result_str)\n",
    "\n",
    "    return result_json\n",
    "\n",
    "#@tracer.start_as_current_span(name=\"rag\")  # Uncomment this line to enable tracing for this function\n",
    "def rag(user_question: str):\n",
    "    \"\"\"\n",
    "    Search the knowledge base and generate an answer to the user's question with the retrieved documents.\n",
    "\n",
    "    :param user_question (str): The original user question.\n",
    "    :return: Answer to the user's question based on the retrieved documents.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    #span = trace.get_current_span()  # Uncomment this line to enable tracing\n",
    "\n",
    "    # Generate search query\n",
    "    search_query = get_search_query(user_question=user_question)\n",
    "    #span.set_attribute(\"search_query\", search_query)  # Uncomment this line to enable tracing\n",
    "\n",
    "    # Retrieve documents with search query\n",
    "    documents = get_documents(search_query=search_query)\n",
    "\n",
    "    # Generate answer based on retrieved documents\n",
    "    answer = get_answer_from_documents(user_question=user_question, documents=documents)\n",
    "    #span.set_attribute(\"answer\", answer[\"answer\"])  # Uncomment this line to enable tracing\n",
    "    #span.set_attribute(\"sources\", answer[\"sources\"])  # Uncomment this line to enable tracing\n",
    "    \n",
    "    return answer[\"answer\"]\n",
    "\n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    rag\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import FunctionTool, ToolSet\n",
    "\n",
    "# Initialize agent toolset with user functions\n",
    "functions = FunctionTool(user_functions)\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an AI assistant for AVL employees helping answering user questions.\n",
    "Use your knowledge base to answer the user questions with the context retrieved from documents.\n",
    "\"\"\"\n",
    "\n",
    "# Create agent with toolset and process a run\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    name=\"avl-knowledge-agent\",\n",
    "    instructions=instructions,\n",
    "    toolset=toolset\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display answer from agent\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "def download_and_save_image(image_file_id: str, image_file_name: str) -> None:\n",
    "    project_client.agents.save_file(file_id=image_file_id, file_name=image_file_name)\n",
    "\n",
    "\n",
    "def pretty_print(message):\n",
    "    role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "    # Check the type of message content and handle accordingly\n",
    "    for content in message.content:\n",
    "        if content.type == \"text\":\n",
    "            message_content = content.text.value\n",
    "            display(Markdown(f\"**{role_label}**: {message_content}\\n\"))\n",
    "            if content.text.annotations:\n",
    "                display(Markdown(\"Sources:\"))\n",
    "                for annotation in content.text.annotations:\n",
    "                    if annotation.type == \"url_citation\":\n",
    "                        display(Markdown(f\"{annotation.text}\\n* Title: {annotation['url_citation']['title']}\\n* URL: {annotation['url_citation']['url']}\"))\n",
    "        elif content.type == \"image_file\":\n",
    "            # Handle image file content, e.g., print the file ID or download the image\n",
    "            image_file_id = content.image_file.file_id\n",
    "            # Define a path to save the image\n",
    "            image_file_name = f\"image_{image_file_id}.png\"\n",
    "            # Download and save the image\n",
    "            download_and_save_image(image_file_id, image_file_name)\n",
    "            # Display the image within Jupyter Notebook\n",
    "            display(Markdown(f\"**{role_label}**: Image {image_file_id} generated\"))\n",
    "            display(Image(filename=image_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create thread for communication\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a message and process agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User prompt\n",
    "user_prompt = \"The customer complained about an issue with a noisy E-Axle. What can I offer?\"\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_prompt,\n",
    ")\n",
    "display(Markdown(f\"**User**: {user_prompt}\\n\"))\n",
    "\n",
    "# Create and process agent run in thread with tools\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "\n",
    "# Check if run has failed\n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Fetch messages\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "agent_message = messages.data[0]\n",
    "pretty_print(agent_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve run steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve run steps\n",
    "run_steps = project_client.agents.list_run_steps(thread_id=thread.id, run_id=run.id)\n",
    "for step in run_steps.data:\n",
    "    if step.step_details.type == \"tool_calls\":\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            if tool_call.type == \"code_interpreter\":\n",
    "                print(\"Used Code Interpreter with:\")\n",
    "                print(tool_call.code_interpreter.input)\n",
    "            elif tool_call.type == \"bing_grounding\":\n",
    "                print(\"Used Bing Grounding tool\")\n",
    "            elif tool_call.type == \"function\":\n",
    "                print(f\"Used function {tool_call.function.name} with arguments:\")\n",
    "                print(tool_call.function.arguments)\n",
    "            print(\"-------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print conversation\n",
    "for message in reversed(messages.data):\n",
    "    pretty_print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the agent when done\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(\"Deleted agent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
