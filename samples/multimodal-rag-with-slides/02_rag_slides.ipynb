{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG with presentation slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai azure-identity azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize clients for Azure AI Search and Azure OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents  import SearchClient\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = \"<your-azure-openai-endpoint>\"\n",
    "AZURE_OPENAI_API_KEY = \"<your-azure-openai-api-key>\"\n",
    "AZURE_AI_SEARCH_ENDPOINT =\"<your-azure-ai-search-endpoint>\"\n",
    "AZURE_AI_SEARCH_ADMIN_KEY = \"<your-azure-ai-search-admin-key>\"\n",
    "\n",
    "# Create a search client to connect to the Azure AI Search service\n",
    "search_client = SearchClient(\n",
    "    index_name=\"docs\",\n",
    "    endpoint=AZURE_AI_SEARCH_ENDPOINT,\n",
    "    credential=AzureKeyCredential(key=AZURE_AI_SEARCH_ADMIN_KEY),\n",
    ")\n",
    "\n",
    "# Create an Azure OpenAI client to connect to the Azure OpenAI service\n",
    "aoai_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-10-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.search.documents.models import QueryAnswerType, QueryCaptionType, QueryType, VectorizedQuery\n",
    "\n",
    "# Define a function to generate a search query\n",
    "def get_search_query(user_question: str):\n",
    "    system_prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    - You are an AI assistant.\n",
    "    - Given the user's question, respond with a search query that can be used to retrieve relevant documents for the user's question based on the intent.\n",
    "    - Be specific in what the user is asking about.\n",
    "    - Provide only the search query in the response.\n",
    "\n",
    "    # Example\n",
    "    With a user query like below:\n",
    "    \"What was the total revenue in 2024?\"\n",
    "\n",
    "    Respond with:\n",
    "    \"total revenue in 2024\"\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Return the search query for the following user question: {user_question}\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    search_query = response.choices[0].message.content\n",
    "\n",
    "    return search_query\n",
    "\n",
    "# Define a function that retrieves documents from the search index based on a search query\n",
    "def get_documents(search_query: str):\n",
    "    # Embed the search query\n",
    "    embedding = aoai_client.embeddings.create(model=\"text-embedding-3-large\", input=search_query)\n",
    "    search_vector = embedding.data[0].embedding\n",
    "\n",
    "    # Search the index for document chunks matching the search query\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=search_vector,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"content_vector\"\n",
    "    )\n",
    "\n",
    "    search_results = search_client.search(\n",
    "        search_text=search_query,\n",
    "        vector_queries=[vector_query],\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"default\",\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=10,\n",
    "        select=[\"id\", \"page\", \"base64_image\", \"content\"]\n",
    "    )\n",
    "\n",
    "    documents = [\n",
    "        {\n",
    "            \"id\": result[\"id\"],\n",
    "            \"page\": result[\"page\"],\n",
    "            \"base64_image\": result[\"base64_image\"],\n",
    "            \"content\": result[\"content\"]\n",
    "        }\n",
    "        for result in search_results\n",
    "    ]\n",
    "\n",
    "    return documents\n",
    "\n",
    "# Define a function that generates an answer with documents\n",
    "def get_answer_from_documents(user_question: str, documents: list):\n",
    "    system_prompt = \"\"\"\n",
    "    - You are an expert helping employees from AVL to find information in the knowledge base of AVL.\n",
    "    - You are given a user question and a set of text descriptions and screenshots of slides from a presentation.\n",
    "    - Use the text descriptions and screenshots as context to answer the questions as completely, correctly, and concisely as possible.\n",
    "    - Not all documents are relevant to the question, so only use the relevant documents to answer the question.\n",
    "    - Don't try to make up any answers. If the answer cannot be retrieved from the context and you do not know the answer, then answer 'Sorry, I do not know.'.\n",
    "    - Add sources to the answer listing the page numbers you used and that are relevant to answer the question.\n",
    "    - The final response must be in JSON format with two fields:\n",
    "        - answer: The generated answer to the user's question.\n",
    "        - sources: A list of page numbers for each cited source\n",
    "    - Do not use ```json```\n",
    "\n",
    "    Here is an example of the final response:\n",
    "    {\n",
    "        \"answer\": \"The total revenue in 2024 was $245,122 million.\"\n",
    "        \"sources\": [1]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    context = \"\\n\\n\".join(f\"Document ID: {document['id']}\\nPage: {document['page']}\\nContent:\\n{document['content']}\" for document in documents)\n",
    "    user_prompt = f\"\"\"User: {user_question}\\n\\n\n",
    "    Answer the user's question based on the following context:\\n\\nDocuments:\\n\\n{context}\"\"\"\n",
    "    user_content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    images = [{ \"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{document['base64_image']}\"} } for document in documents]\n",
    "    user_content += images\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    result_str = response.choices[0].message.content\n",
    "    result_json = json.loads(result_str)\n",
    "\n",
    "    return result_json\n",
    "\n",
    "# RAG pipeline function\n",
    "def rag(user_question: str):\n",
    "    # Generate search query\n",
    "    search_query = get_search_query(user_question=user_question)\n",
    "\n",
    "    # Retrieve documents with search query\n",
    "    documents = get_documents(search_query=search_query)\n",
    "\n",
    "    # Generate answer based on retrieved documents\n",
    "    answer = get_answer_from_documents(user_question=user_question, documents=documents)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer[\"answer\"], \"documents\": documents, \"sources\": answer[\"sources\"], \"search_query\": search_query\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "user_question = \"The customer complained about an issue with a noisy E-Axle. What can I offer?\"\n",
    "\n",
    "result = rag(user_question=user_question)\n",
    "display(Markdown(f\"ðŸ”Ž Search Query: {result['search_query']}\"))\n",
    "display(Markdown(f\"ðŸ’¬ Answer: {result['answer']}\"))\n",
    "display(Markdown(f\"ðŸ“• Sources: {result['sources']}\"))\n",
    "for document in result['documents']:\n",
    "    print(f\"Document ID: {document['id']}\")\n",
    "    display(Image(base64.b64decode(document[\"base64_image\"])))\n",
    "    print(100 * \"-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
